{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1: Exploración y Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploración Inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Most Streamed Spotify Songs 2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrecuencia de valores únicos:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdf2[col]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Llamar a la función con las rutas de tus archivos CSV\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m exploracion_inicial(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMost Streamed Spotify Songs 2023.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMost Streamed Spotify Songs 2024.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mexploracion_inicial\u001b[1;34m(csv1_path, csv2_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexploracion_inicial\u001b[39m(csv1_path, csv2_path):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# Intentar leer los archivos CSV con la codificación 'utf-8'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m         df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv1_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m         df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv2_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Si hay un error de decodificación, intentar con 'latin1'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanmo\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\sanmo\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\sanmo\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\sanmo\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\sanmo\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Most Streamed Spotify Songs 2023.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "def exploracion_inicial(csv1_path, csv2_path):\n",
    "    try:\n",
    "        # Intentar leer los archivos CSV con la codificación 'utf-8'\n",
    "        df1 = pd.read_csv(csv1_path, encoding='utf-8', on_bad_lines='skip', delimiter= ';')\n",
    "        df2 = pd.read_csv(csv2_path, encoding='utf-8', on_bad_lines='skip')\n",
    "    except UnicodeDecodeError:\n",
    "        # Si hay un error de decodificación, intentar con 'latin1'\n",
    "        df1 = pd.read_csv(csv1_path, encoding='latin1', on_bad_lines='skip')\n",
    "        df2 = pd.read_csv(csv2_path, encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "    print(\"------------- Información del primer DataFrame (2023) --------------\")\n",
    "    print(f\"Forma: {df1.shape}\")\n",
    "    print(f\"Número de dimensiones: {df1.ndim}\")\n",
    "    print(f\"Número de elementos: {df1.size}\")\n",
    "    print(f\"Tipos de datos:\\n{df1.dtypes}\\n\")\n",
    "    print(\"Primeras filas:\\n\", df1.head(), \"\\n\")\n",
    "    print(df1.info())\n",
    "\n",
    "    print(\"------------- Información del segundo DataFrame (2024) --------------\")\n",
    "    print(f\"Forma: {df2.shape}\")\n",
    "    print(f\"Número de dimensiones: {df2.ndim}\")\n",
    "    print(f\"Número de elementos: {df2.size}\")\n",
    "    print(f\"Tipos de datos:\\n{df2.dtypes}\\n\")\n",
    "    print(\"Primeras filas:\\n\", df2.head(), \"\\n\")\n",
    "    print(df2.info())\n",
    "\n",
    "    # Identificar valores nulos\n",
    "    print(\"------------- Valores nulos en el primer DataFrame --------------\")\n",
    "    print(df1.isnull().sum(), \"\\n\")\n",
    "\n",
    "    print(\"------------- Valores nulos en el segundo DataFrame --------------\")\n",
    "    print(df2.isnull().sum(), \"\\n\")\n",
    "\n",
    "    # Estadísticas básicas\n",
    "    print(\"------------- Estadísticas descriptivas del primer DataFrame --------------\")\n",
    "    print(df1.describe().T, \"\\n\")\n",
    "\n",
    "    print(\"------------- Estadísticas descriptivas del segundo DataFrame --------------\")\n",
    "    print(df2.describe().T, \"\\n\")\n",
    "\n",
    "    # Identificar columnas categóricas y numéricas en df1\n",
    "    cat_cols_df1 = df1.select_dtypes(include=['object', 'category']).columns\n",
    "    num_cols_df1 = df1.select_dtypes(include=['number']).columns\n",
    "\n",
    "    print(f\"Columnas categóricas en el primer DataFrame: {cat_cols_df1}\")\n",
    "    print(f\"Columnas numéricas en el primer DataFrame: {num_cols_df1}\\n\")\n",
    "\n",
    "    # Identificar columnas categóricas y numéricas en df2\n",
    "    cat_cols_df2 = df2.select_dtypes(include=['object', 'category']).columns\n",
    "    num_cols_df2 = df2.select_dtypes(include=['number']).columns\n",
    "\n",
    "    print(f\"Columnas categóricas en el segundo DataFrame: {cat_cols_df2}\")\n",
    "    print(f\"Columnas numéricas en el segundo DataFrame: {num_cols_df2}\\n\")\n",
    "\n",
    "    # Análisis de columnas categóricas en df1\n",
    "    for col in cat_cols_df1:\n",
    "        print(f\"----------- Análisis de la columna categórica '{col}' en el primer DataFrame -----------\")\n",
    "        print(f\"Valores únicos:\\n{df1[col].unique()}\\n\")\n",
    "        print(f\"Total de valores únicos:\\n{df1[col].nunique()}\\n\")\n",
    "        print(f\"Frecuencia de valores únicos:\\n{df1[col].value_counts()}\\n\")\n",
    "\n",
    "    # Análisis de columnas categóricas en df2\n",
    "    for col in cat_cols_df2:\n",
    "        print(f\"----------- Análisis de la columna categórica '{col}' en el segundo DataFrame -----------\")\n",
    "        print(f\"Valores únicos:\\n{df2[col].unique()}\\n\")\n",
    "        print(f\"Total de valores únicos:\\n{df2[col].nunique()}\\n\")\n",
    "        print(f\"Frecuencia de valores únicos:\\n{df2[col].value_counts()}\\n\")\n",
    "\n",
    "# Llamar a la función con las rutas de tus archivos CSV\n",
    "exploracion_inicial('Most Streamed Spotify Songs 2023.csv', 'Most Streamed Spotify Songs 2024.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentaje de valores nulos del segundo Dataframe por columna:\n",
      "\n",
      "Track                          1.24\n",
      "Album Name                     1.00\n",
      "Artist                         0.46\n",
      "Release Date                   0.00\n",
      "ISRC                           0.00\n",
      "All Time Rank                  0.00\n",
      "Track Score                    0.00\n",
      "Spotify Streams                2.46\n",
      "Spotify Playlist Count         1.52\n",
      "Spotify Playlist Reach         1.57\n",
      "Spotify Popularity            17.49\n",
      "YouTube Views                  6.70\n",
      "YouTube Likes                  6.85\n",
      "TikTok Posts                  25.51\n",
      "TikTok Likes                  21.31\n",
      "TikTok Views                  21.34\n",
      "YouTube Playlist Reach        21.94\n",
      "Apple Music Playlist Count    12.20\n",
      "Deezer Playlist Count         20.03\n",
      "Deezer Playlist Reach         20.18\n",
      "Amazon Playlist Count         22.94\n",
      "Pandora Streams               24.05\n",
      "Pandora Track Stations        27.58\n",
      "Soundcloud Streams             0.00\n",
      "Shazam Counts                 12.55\n",
      "Explicit Track                 0.00\n",
      "dtype: float64\n",
      "\n",
      "--------------------------------------------\n",
      "DataFrame 2023 limpio:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 953 entries, 0 to 952\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                                                                                                                              Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                                                                                                                              --------------  ----- \n",
      " 0   track_name,artist(s)_name,artist_count,released_year,released_month,released_day,in_spotify_playlists,in_spotify_charts,streams,in_apple_playlists,in_apple_charts,in_deezer_playlists,in_deezer_charts,in_shazam_charts,bpm,key,mode,danceability_%,valence_%,energy_%,acousticness_%,instrumentalness_%,liveness_%,speechiness_%  953 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.6+ KB\n",
      "None\n",
      "\n",
      "Forma: (953, 1)\n",
      "\n",
      "Número de elementos: 953\n",
      "\n",
      "--------------------------------------------\n",
      "DataFrame 2024 limpio:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4598 entries, 0 to 4597\n",
      "Data columns (total 26 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Track                       4541 non-null   object \n",
      " 1   Album Name                  4552 non-null   object \n",
      " 2   Artist                      4577 non-null   object \n",
      " 3   Release Date                4598 non-null   object \n",
      " 4   ISRC                        4598 non-null   object \n",
      " 5   All Time Rank               4598 non-null   object \n",
      " 6   Track Score                 4598 non-null   float64\n",
      " 7   Spotify Streams             4485 non-null   object \n",
      " 8   Spotify Playlist Count      4528 non-null   object \n",
      " 9   Spotify Playlist Reach      4526 non-null   object \n",
      " 10  Spotify Popularity          3794 non-null   float64\n",
      " 11  YouTube Views               4290 non-null   object \n",
      " 12  YouTube Likes               4283 non-null   object \n",
      " 13  TikTok Posts                3425 non-null   object \n",
      " 14  TikTok Likes                3618 non-null   object \n",
      " 15  TikTok Views                3617 non-null   object \n",
      " 16  YouTube Playlist Reach      3589 non-null   object \n",
      " 17  Apple Music Playlist Count  4037 non-null   float64\n",
      " 18  Deezer Playlist Count       3677 non-null   float64\n",
      " 19  Deezer Playlist Reach       3670 non-null   object \n",
      " 20  Amazon Playlist Count       3543 non-null   float64\n",
      " 21  Pandora Streams             3492 non-null   object \n",
      " 22  Pandora Track Stations      3330 non-null   object \n",
      " 23  Soundcloud Streams          4598 non-null   float64\n",
      " 24  Shazam Counts               4021 non-null   object \n",
      " 25  Explicit Track              4598 non-null   int64  \n",
      "dtypes: float64(6), int64(1), object(19)\n",
      "memory usage: 934.1+ KB\n",
      "None\n",
      "\n",
      "Forma: (4598, 26)\n",
      "\n",
      "Número de elementos: 119548\n",
      "CSV limpio guardado como archivo_limpio.csv\n",
      "CSV limpio guardado como archivo_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "# Une los dos archivos de datos en un mismo DataFrame basado en 'Loyalty Number'.\n",
    "# Luego, analiza los valores nulos y limpia los DataFrames df1 y df2.\n",
    "\n",
    "# Leer los archivos CSV\n",
    "try:\n",
    "        # Intentar leer los archivos CSV con la codificación 'utf-8'\n",
    "        df23 = pd.read_csv('Most Streamed Spotify Songs 2023.csv', encoding='utf-8', on_bad_lines='skip', delimiter= ';')\n",
    "        df24 = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='utf-8', on_bad_lines='skip')\n",
    "except UnicodeDecodeError:\n",
    "        # Si hay un error de decodificación, intentar con 'latin1'\n",
    "        df23 = pd.read_csv('Most Streamed Spotify Songs 2023.csv', encoding='latin1', on_bad_lines='skip')\n",
    "        df24 = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# 1. Eliminar duplicados DFs\n",
    "df23= df23.drop_duplicates()\n",
    "df24= df24.drop_duplicates()\n",
    "\n",
    "# 2. Eliminar la columna 'Tidal'\n",
    "# df24 = df24.drop(columns=['TIDAL Popularity'])\n",
    "\n",
    "\n",
    "# 4. Verificar el porcentaje de valores nulos en el DataFrame\n",
    "porc_nulos = round((df24.isnull().sum() / df24.shape[0]) * 100, 2)\n",
    "print(\"\\nPorcentaje de valores nulos del segundo Dataframe por columna:\")\n",
    "print(f\"\\n{porc_nulos}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--------------------------------------------\")\n",
    "print(\"DataFrame 2023 limpio:\")\n",
    "# Verificar los cambios\n",
    "print(df23.info())\n",
    "print(f\"\\nForma: {df23.shape}\")\n",
    "print(f\"\\nNúmero de elementos: {df23.size}\")\n",
    "\n",
    "print(\"\\n--------------------------------------------\")\n",
    "print(\"DataFrame 2024 limpio:\")\n",
    "# Verificar los cambios\n",
    "print(df24.info())\n",
    "print(f\"\\nForma: {df24.shape}\")\n",
    "print(f\"\\nNúmero de elementos: {df24.size}\")\n",
    "\n",
    "# Guardar el CSV limpio\n",
    "df23.to_csv('Most Streamed Spotify Songs 2023.csv', index=False)\n",
    "print(\"CSV limpio guardado como archivo_limpio.csv\")\n",
    "\n",
    "df24.to_csv('Most Streamed Spotify Songs 2024.csv', index=False)\n",
    "print(\"CSV limpio guardado como archivo_limpio.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma: (4598, 26)\n",
      "\n",
      "Número de elementos: 119548\n",
      "CSV limpio guardado como archivo_limpio.csv\n",
      "CSV limpio guardado como 'Most Streamed Spotify Songs 2023.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_2252\\1331087699.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df24['Soundcloud Streams'].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Limpia el archivo CSV 'Most Streamed Spotify Songs 2024.csv' para asegurar la consistencia y legibilidad de los datos.\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# Cargar el CSV limpio\n",
    "try:\n",
    "        # Intentar leer los archivos CSV con la codificación 'utf-8'\n",
    "        df23 = pd.read_csv('Most Streamed Spotify Songs 2023.csv', encoding='utf-8', on_bad_lines='skip', delimiter= ';')\n",
    "        df24 = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='utf-8', on_bad_lines='skip')\n",
    "except UnicodeDecodeError:\n",
    "        # Si hay un error de decodificación, intentar con 'latin1'\n",
    "        df23 = pd.read_csv('Most Streamed Spotify Songs 2023.csv', encoding='latin1', on_bad_lines='skip')\n",
    "        df24 = pd.read_csv('Most Streamed Spotify Songs 2024.csv', encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# 1. Eliminar columnas 'SiriusXM Spins' y 'AirPlay Spins' ya que o tienen muchos valores nulos\n",
    "# o no aportan información relevante\n",
    "# df24 = df24.drop(columns=['SiriusXM Spins', 'AirPlay Spins']) \n",
    "\n",
    "# 2. Convertir la columna 'Soundcloud Streams' a numérica, reemplazando los valores no convertibles por NaN\n",
    "df24['Soundcloud Streams'] = pd.to_numeric(df24['Soundcloud Streams'], errors='coerce')\n",
    "\n",
    "# Reemplazar valores nulos en 'Soundcloud Streams' por la media\n",
    "mean_value = df24['Soundcloud Streams'].mean()\n",
    "df24['Soundcloud Streams'].fillna(mean_value, inplace=True)\n",
    "\n",
    "\n",
    "# 3. Función para limpiar texto\n",
    "def limpiar_texto(texto):\n",
    "    if isinstance(texto, str):\n",
    "        # Eliminar caracteres extraños usando una expresión regular\n",
    "        texto_limpio = re.sub(r'[^a-zA-Z0-9\\s]', '', texto)\n",
    "        # Eliminar espacios en blanco extra\n",
    "        texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()\n",
    "        return texto_limpio\n",
    "    return texto\n",
    "\n",
    "\n",
    "df24['Track'] = df24['Track'].apply(limpiar_texto)\n",
    "df24['Album Name'] = df24['Album Name'].apply(limpiar_texto)\n",
    "df24['Artist'] = df24['Artist'].apply(limpiar_texto)\n",
    "\n",
    "\n",
    "# Verificar los cambios\n",
    "print(f\"\\nForma: {df24.shape}\")\n",
    "print(f\"\\nNúmero de elementos: {df24.size}\")\n",
    "df24.head()  # Visualizar las primeras filas\n",
    "\n",
    "\n",
    "df24.to_csv('Most Streamed Spotify Songs 2024.csv', index=False)\n",
    "print(\"CSV limpio guardado como archivo_limpio.csv\")\n",
    "\n",
    "# Guardar el CSV limpio\n",
    "df23.to_csv('Most Streamed Spotify Songs 2023.csv', index=False)\n",
    "print(\"CSV limpio guardado como 'Most Streamed Spotify Songs 2023.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
